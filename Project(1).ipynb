{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f091739a",
   "metadata": {},
   "source": [
    "## **Data Intialisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b1630c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6eeff457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4031c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('tweet_emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f2faa5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "535fcd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc3b07f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise',\n",
       "       'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "08e37f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8638\n",
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "720420a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with other emotion labels\n",
    "df=df.drop(df[df.sentiment=='anger'].index)\n",
    "df=df.drop(df[df.sentiment=='boredom'].index)\n",
    "df=df.drop(df[df.sentiment=='enthusiasm'].index)\n",
    "df=df.drop(df[df.sentiment=='empty'].index)\n",
    "df=df.drop(df[df.sentiment=='fun'].index)\n",
    "df=df.drop(df[df.sentiment=='surprise'].index)\n",
    "df=df.drop(df[df.sentiment=='relief'].index)\n",
    "df=df.drop(df[df.sentiment=='hate'].index)\n",
    "df=df.drop(df[df.sentiment=='neutral'].index)\n",
    "df=df.drop(df[df.sentiment=='worry'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a8003f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"tweet_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b6725b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            content\n",
       "1   sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2   sadness                Funeral ceremony...gloomy friday...\n",
       "6   sadness  I should be sleep, but im not! thinking about ...\n",
       "8   sadness            @charviray Charlene my love. I miss you\n",
       "9   sadness         @kelcouch I'm sorry  at least it's Friday?"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb8a57e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happiness    5209\n",
       "sadness      5165\n",
       "love         3842\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0efbe50",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a416d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#Encoding output labels 'sadness' as '1' & 'happiness' as '0'\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "df['label']= lbl_enc.fit_transform(df.sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ab855a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happiness    5209\n",
      "sadness      5165\n",
      "love         3842\n",
      "Name: sentiment, dtype: int64\n",
      "0    5209\n",
      "2    5165\n",
      "1    3842\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['sentiment'].value_counts())\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "13205481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding output labels 'happiness' as '0' \n",
    "#Encoding output labels 'sadness' as '1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f67f2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making all review to lowercase\n",
    "df['content']=df['content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7c1eacaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-d97f42024aeb>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['content'] = df['content'].str.replace('[^\\w\\s]',' ')\n"
     ]
    }
   ],
   "source": [
    "# Removing Punctuation, Symbols\n",
    "df['content'] = df['content'].str.replace('[^\\w\\s]',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "022cdefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "stops.remove(\"not\")\n",
    "stops.remove(\"but\")\n",
    "stops.remove(\"no\")\n",
    "df['content'] = df['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0448ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#Correcting Letter Repetitions\n",
    "def de_repeat(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7b889057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to find the top 10,000 rarest words appearing in the data\n",
    "freq = pd.Series(' '.join(df['content']).split()).value_counts()[-10000:]\n",
    "\n",
    "# Removing all those rarely appearing words from the data\n",
    "freq = list(freq.index)\n",
    "df['content'] = df['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "74e778d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>n bed headache ughh waitin call</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>funeral ceremony gloomy friday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sadness</td>\n",
       "      <td>sleep but im not thinking old friend want but ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sadness</td>\n",
       "      <td>charviray love miss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sadness</td>\n",
       "      <td>sorry least friday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            content  label\n",
       "1   sadness                    n bed headache ughh waitin call      2\n",
       "2   sadness                     funeral ceremony gloomy friday      2\n",
       "6   sadness  sleep but im not thinking old friend want but ...      2\n",
       "8   sadness                                charviray love miss      2\n",
       "9   sadness                                 sorry least friday      2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "957d9776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to split string into tokens\n",
    "def identify_tokens(row):\n",
    "    tokens=nltk.word_tokenize(row)\n",
    "    token_words=[w for w in tokens if w.isalpha()]\n",
    "    return token_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dffb779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization of dataframe\n",
    "df['content']=df[\"content\"].apply(identify_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0c5e3e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#Function for Lemmatizing the list of words\n",
    "def lem_list(row):\n",
    "    lemmatized_list = [lemmatizer.lemmatize(word) for word in row]\n",
    "    return(lemmatized_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a8845587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize of the dataframe\n",
    "def rejoin_words(row):\n",
    "    joined_words = (\" \".join(row))\n",
    "    return joined_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2c118853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining the processed words in the data_frame\n",
    "df['content'] = df[\"content\"].apply(rejoin_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b09c5ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>n bed headache ughh waitin call</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>funeral ceremony gloomy friday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sadness</td>\n",
       "      <td>sleep but im not thinking old friend want but ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sadness</td>\n",
       "      <td>charviray love miss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sadness</td>\n",
       "      <td>sorry least friday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            content  label\n",
       "1   sadness                    n bed headache ughh waitin call      2\n",
       "2   sadness                     funeral ceremony gloomy friday      2\n",
       "6   sadness  sleep but im not thinking old friend want but ...      2\n",
       "8   sadness                                charviray love miss      2\n",
       "9   sadness                                 sorry least friday      2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9809703",
   "metadata": {},
   "source": [
    "# Splitting dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c065873",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8d118aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1_train,x1_test,y1_train,y1_test = train_test_split(df[['content']],df[['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e7f74efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3554, 1)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "63e7933d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10662, 1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8473178d",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41f47c2",
   "metadata": {},
   "source": [
    "# TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a4ca8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8ab8cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting TF-IDF parameters\n",
    "tfidf = TfidfVectorizer(max_features=1000, analyzer='word', ngram_range=(1,3))\n",
    "x_train_tfidf = tfidf.fit_transform(x_train)\n",
    "x_val_tfidf = tfidf.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86730d59",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "59a10235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bb23a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Count Vectors Parameters\n",
    "count_vect = CountVectorizer(analyzer='word')\n",
    "count_vect.fit(df['content'])\n",
    "x_train_count = count_vect.transform(x_train)\n",
    "x_val_count = count_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe89b61",
   "metadata": {},
   "source": [
    "# Feature Extracton using Lexical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ef5450cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.3.2)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2020.12.5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade vaderSentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1d4c2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "719cf58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24157</th>\n",
       "      <td>got alot around today get job app completed fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21039</th>\n",
       "      <td>thanks follow loving energy site help but draw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19130</th>\n",
       "      <td>damnit sucks one ones thought drag back lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33954</th>\n",
       "      <td>rap second sat moviess haha quot swim lake sex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>wan na go concert thailand really wan na go mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content\n",
       "24157  got alot around today get job app completed fi...\n",
       "21039  thanks follow loving energy site help but draw...\n",
       "19130        damnit sucks one ones thought drag back lol\n",
       "33954  rap second sat moviess haha quot swim lake sex...\n",
       "1735   wan na go concert thailand really wan na go mu..."
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8fdc3fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train['negative'] = x1_train['content'].apply(lambda x: analyser.polarity_scores(x)[\"neg\"])\n",
    "x1_test['negative'] = x1_test['content'].apply(lambda x: analyser.polarity_scores(x)[\"neg\"])\n",
    "x1_train['positive'] = x1_train['content'].apply(lambda x: analyser.polarity_scores(x)[\"pos\"])\n",
    "x1_test['positive'] = x1_test['content'].apply(lambda x: analyser.polarity_scores(x)[\"pos\"])\n",
    "x1_train['neutral'] = x1_train['content'].apply(lambda x: analyser.polarity_scores(x)[\"neu\"])\n",
    "x1_test['neutral'] = x1_test['content'].apply(lambda x: analyser.polarity_scores(x)[\"neu\"])\n",
    "x1_train['compound'] = x1_train['content'].apply(lambda x: analyser.polarity_scores(x)[\"compound\"])\n",
    "x1_test['compound'] = x1_test['content'].apply(lambda x: analyser.polarity_scores(x)[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9257ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "x1_train['subjectivity'] = x1_train['content'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "x1_test['subjectivity'] = x1_test['content'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "x1_train['polarity'] = x1_train['content'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "x1_test['polarity'] = x1_test['content'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1ba8c1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                  content  negative  positive  \\\n",
       "24157  got alot around today get job app completed fi...     0.000     0.214   \n",
       "21039  thanks follow loving energy site help but draw...     0.000     0.527   \n",
       "19130        damnit sucks one ones thought drag back lol     0.534     0.192   \n",
       "33954  rap second sat moviess haha quot swim lake sex...     0.000     0.200   \n",
       "1735   wan na go concert thailand really wan na go mu...     0.147     0.000   \n",
       "...                                                  ...       ...       ...   \n",
       "25767  good morning everyone nice see today hope wond...     0.000     0.752   \n",
       "24072  haha not know work blip apart thanks song nice...     0.000     0.521   \n",
       "34470                                  heading nadia yee     0.000     0.000   \n",
       "37631  chris pine zachary quinto leonard nimoy snl to...     0.000     0.216   \n",
       "37609                         dyed hair back super black     0.000     0.494   \n",
       "\n",
       "       neutral  compound  subjectivity  polarity  \n",
       "24157    0.786    0.4588      1.000000  0.500000  \n",
       "21039    0.473    0.7003      0.575000  0.400000  \n",
       "19130    0.274   -0.6124      0.267708  0.100000  \n",
       "33954    0.800    0.4588      0.183333 -0.016667  \n",
       "1735     0.853   -0.2263      0.150000 -0.200000  \n",
       "...        ...       ...           ...       ...  \n",
       "25767    0.248    0.9349      0.900000  0.637500  \n",
       "24072    0.479    0.8271      0.500000  0.333333  \n",
       "34470    1.000    0.0000      0.000000  0.000000  \n",
       "37631    0.784    0.5542      0.300000  0.125000  \n",
       "37609    0.506    0.5994      0.366667  0.055556  \n",
       "\n",
       "[10662 rows x 7 columns]>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4abe83e",
   "metadata": {},
   "source": [
    "# **Training of Models**\n",
    "## **I)Using TF-IDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e398bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "85ac4bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38938618925831203\n",
      "[[742 510 696]\n",
      " [220 289 179]\n",
      " [772 488 796]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.38      0.40      1948\n",
      "           1       0.22      0.42      0.29       688\n",
      "           2       0.48      0.39      0.43      2056\n",
      "\n",
      "    accuracy                           0.39      4692\n",
      "   macro avg       0.38      0.40      0.37      4692\n",
      "weighted avg       0.42      0.39      0.40      4692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Multinomial Naive Bayes Classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_tfidf, y_train)\n",
    "y_pred = nb.predict(x_val_tfidf)\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "252c0277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3998294970161978\n",
      "[[ 568  362  483]\n",
      " [  87  157   37]\n",
      " [1079  768 1151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.40      0.36      1413\n",
      "           1       0.12      0.56      0.20       281\n",
      "           2       0.69      0.38      0.49      2998\n",
      "\n",
      "    accuracy                           0.40      4692\n",
      "   macro avg       0.38      0.45      0.35      4692\n",
      "weighted avg       0.55      0.40      0.44      4692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Linear SVM\n",
    "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
    "lsvm.fit(x_train_tfidf, y_train)\n",
    "y_pred = lsvm.predict(x_val_tfidf)\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4d137ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3874680306905371\n",
      "[[748 522 688]\n",
      " [184 246 159]\n",
      " [802 519 824]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.38      0.41      1958\n",
      "           1       0.19      0.42      0.26       589\n",
      "           2       0.49      0.38      0.43      2145\n",
      "\n",
      "    accuracy                           0.39      4692\n",
      "   macro avg       0.37      0.39      0.37      4692\n",
      "weighted avg       0.43      0.39      0.40      4692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Logistic Regression\n",
    "logreg = LogisticRegression(C=1)\n",
    "logreg.fit(x_train_tfidf, y_train)\n",
    "y_pred = logreg.predict(x_val_tfidf)\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4b00fe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38491048593350385\n",
      "[[817 574 764]\n",
      " [177 216 134]\n",
      " [740 497 773]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.38      0.42      2155\n",
      "           1       0.17      0.41      0.24       527\n",
      "           2       0.46      0.38      0.42      2010\n",
      "\n",
      "    accuracy                           0.38      4692\n",
      "   macro avg       0.37      0.39      0.36      4692\n",
      "weighted avg       0.43      0.38      0.40      4692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 4: Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(x_train_tfidf, y_train)\n",
    "y_pred = rf.predict(x_val_tfidf)\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a960db93",
   "metadata": {},
   "source": [
    "## **II) Using Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "45cb3ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6293691389599319\n",
      "[[1042  441  266]\n",
      " [ 338  609  103]\n",
      " [ 354  237 1302]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60      1749\n",
      "           1       0.47      0.58      0.52      1050\n",
      "           2       0.78      0.69      0.73      1893\n",
      "\n",
      "    accuracy                           0.63      4692\n",
      "   macro avg       0.62      0.62      0.62      4692\n",
      "weighted avg       0.64      0.63      0.63      4692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Multinomial Naive Bayes Classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_count, y_train)\n",
    "y_pred = nb.predict(x_val_count)\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "43708d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6413043478260869\n",
      "[[1122  497  252]\n",
      " [ 230  533   65]\n",
      " [ 382  257 1354]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.62      1871\n",
      "           1       0.41      0.64      0.50       828\n",
      "           2       0.81      0.68      0.74      1993\n",
      "\n",
      "    accuracy                           0.64      4692\n",
      "   macro avg       0.62      0.64      0.62      4692\n",
      "weighted avg       0.68      0.64      0.65      4692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Linear SVM\n",
    "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
    "lsvm.fit(x_train_count, y_train)\n",
    "y_pred = lsvm.predict(x_val_count)\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6fd1e320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6216965046888321\n",
      "[[1060  479  296]\n",
      " [ 338  596  114]\n",
      " [ 336  212 1261]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59      1835\n",
      "           1       0.46      0.57      0.51      1048\n",
      "           2       0.75      0.70      0.72      1809\n",
      "\n",
      "    accuracy                           0.62      4692\n",
      "   macro avg       0.61      0.61      0.61      4692\n",
      "weighted avg       0.63      0.62      0.63      4692\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Logistic Regression\n",
    "logreg = LogisticRegression(C=1)\n",
    "logreg.fit(x_train_count, y_train)\n",
    "y_pred = logreg.predict(x_val_count)\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "19c2c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6378942881500427\n",
      "[[1055  470  240]\n",
      " [ 293  576   69]\n",
      " [ 386  241 1362]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.60      1765\n",
      "           1       0.45      0.61      0.52       938\n",
      "           2       0.82      0.68      0.74      1989\n",
      "\n",
      "    accuracy                           0.64      4692\n",
      "   macro avg       0.62      0.63      0.62      4692\n",
      "weighted avg       0.66      0.64      0.65      4692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 4: Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(x_train_count, y_train)\n",
    "y_pred = rf.predict(x_val_count)\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f11a8",
   "metadata": {},
   "source": [
    "## **III) Using Vader Sentiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d89f7d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5258863252673045\n",
      "[[ 505  439   91]\n",
      " [ 258  246   72]\n",
      " [ 522  303 1118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.49      0.44      1035\n",
      "           1       0.25      0.43      0.31       576\n",
      "           2       0.87      0.58      0.69      1943\n",
      "\n",
      "    accuracy                           0.53      3554\n",
      "   macro avg       0.50      0.50      0.48      3554\n",
      "weighted avg       0.63      0.53      0.56      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Linear SVM\n",
    "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
    "lsvm.fit(x1_train.drop(['content'], axis=1), y1_train)\n",
    "y_pred = lsvm.predict(x1_test.drop(['content'], axis=1))\n",
    "print(accuracy_score(y_pred, y1_test))\n",
    "print(confusion_matrix(y_pred, y1_test))\n",
    "print(classification_report(y_pred, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "767e1825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.544456949915588\n",
      "[[874 697 295]\n",
      " [ 83 108  33]\n",
      " [328 183 953]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.47      0.55      1866\n",
      "           1       0.11      0.48      0.18       224\n",
      "           2       0.74      0.65      0.69      1464\n",
      "\n",
      "    accuracy                           0.54      3554\n",
      "   macro avg       0.51      0.53      0.48      3554\n",
      "weighted avg       0.67      0.54      0.59      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Logistic Regression\n",
    "logreg = LogisticRegression(C=1)\n",
    "logreg.fit(x1_train.drop(['content'], axis=1), y1_train)\n",
    "y_pred = logreg.predict(x1_test.drop(['content'], axis=1))\n",
    "print(accuracy_score(y_pred, y1_test))\n",
    "print(confusion_matrix(y_pred, y1_test))\n",
    "print(classification_report(y_pred, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3c4da4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-155-34acea675e39>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(x1_train.drop(['content'], axis=1), y1_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5506471581316826\n",
      "[[761 459 369]\n",
      " [293 373  89]\n",
      " [231 156 823]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.48      0.53      1589\n",
      "           1       0.38      0.49      0.43       755\n",
      "           2       0.64      0.68      0.66      1210\n",
      "\n",
      "    accuracy                           0.55      3554\n",
      "   macro avg       0.54      0.55      0.54      3554\n",
      "weighted avg       0.56      0.55      0.55      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(x1_train.drop(['content'], axis=1), y1_train)\n",
    "y_pred = rf.predict(x1_test.drop(['content'], axis=1))\n",
    "print(accuracy_score(y_pred, y1_test))\n",
    "print(confusion_matrix(y_pred, y1_test))\n",
    "print(classification_report(y_pred, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53cac029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here maximum accuracy is obtained when we use count vectorizer features and Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732993a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
